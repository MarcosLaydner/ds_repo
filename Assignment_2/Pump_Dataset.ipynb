{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pump Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPss2hUU5dgx8HXIc6MIaYu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcosLaydner/ds_repo/blob/master/Assignment_2/Pump_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVJrATuDgaNt",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Enviroment preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVZvC0j52Zr_",
        "colab_type": "code",
        "outputId": "fb92189b-edd1-44e7-d63e-19b0be6c6416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install -U scikit-multiflow\n",
        "from skmultiflow.meta import LearnNSE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-multiflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/d0/d73be8c424e116862f26cf4e0f99c41e4f0982519aa7bb923c715f05c166/scikit_multiflow-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (16.3MB)\n",
            "\u001b[K     |████████████████████████████████| 16.3MB 75.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-multiflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->scikit-multiflow) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.0->scikit-multiflow) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21.0->scikit-multiflow) (1.12.0)\n",
            "Installing collected packages: scikit-multiflow\n",
            "Successfully installed scikit-multiflow-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWPk_kzH5oZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Kaggle library\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Upload kaggle API key file if needed\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# moves json file so the download commands works properly\n",
        "# !cp kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "# Or alternatively, type your credentials into the following variables\n",
        "os.environ['KAGGLE_USERNAME'] = \"user\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"key\" # key from the json file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPf-guWGgwFk",
        "colab_type": "text"
      },
      "source": [
        "# Dataset download, storage and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHceVfC58i51",
        "colab_type": "code",
        "outputId": "41cf6bde-297c-43eb-ecae-40af347f42dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "!kaggle datasets download -d nphantawee/pump-sensor-data\n",
        "zip_file = ZipFile('pump-sensor-data.zip')\n",
        "df = pd.read_csv(zip_file.open('sensor.csv'))\n",
        "\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pump-sensor-data.zip to /content\n",
            " 27% 10.0M/37.1M [00:00<00:00, 33.9MB/s]\n",
            "100% 37.1M/37.1M [00:00<00:00, 93.8MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sensor_00</th>\n",
              "      <th>sensor_01</th>\n",
              "      <th>sensor_02</th>\n",
              "      <th>sensor_03</th>\n",
              "      <th>sensor_04</th>\n",
              "      <th>sensor_05</th>\n",
              "      <th>sensor_06</th>\n",
              "      <th>sensor_07</th>\n",
              "      <th>sensor_08</th>\n",
              "      <th>sensor_09</th>\n",
              "      <th>sensor_10</th>\n",
              "      <th>sensor_11</th>\n",
              "      <th>sensor_12</th>\n",
              "      <th>sensor_13</th>\n",
              "      <th>sensor_14</th>\n",
              "      <th>sensor_15</th>\n",
              "      <th>sensor_16</th>\n",
              "      <th>sensor_17</th>\n",
              "      <th>sensor_18</th>\n",
              "      <th>sensor_19</th>\n",
              "      <th>sensor_20</th>\n",
              "      <th>sensor_21</th>\n",
              "      <th>sensor_22</th>\n",
              "      <th>sensor_23</th>\n",
              "      <th>sensor_24</th>\n",
              "      <th>sensor_25</th>\n",
              "      <th>sensor_26</th>\n",
              "      <th>sensor_27</th>\n",
              "      <th>sensor_28</th>\n",
              "      <th>sensor_29</th>\n",
              "      <th>sensor_30</th>\n",
              "      <th>sensor_31</th>\n",
              "      <th>sensor_32</th>\n",
              "      <th>sensor_33</th>\n",
              "      <th>sensor_34</th>\n",
              "      <th>sensor_35</th>\n",
              "      <th>sensor_36</th>\n",
              "      <th>sensor_37</th>\n",
              "      <th>sensor_38</th>\n",
              "      <th>sensor_39</th>\n",
              "      <th>sensor_40</th>\n",
              "      <th>sensor_41</th>\n",
              "      <th>sensor_42</th>\n",
              "      <th>sensor_43</th>\n",
              "      <th>sensor_44</th>\n",
              "      <th>sensor_45</th>\n",
              "      <th>sensor_46</th>\n",
              "      <th>sensor_47</th>\n",
              "      <th>sensor_48</th>\n",
              "      <th>sensor_49</th>\n",
              "      <th>sensor_50</th>\n",
              "      <th>sensor_51</th>\n",
              "      <th>machine_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2018-04-01 00:00:00</td>\n",
              "      <td>2.465394</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.310760</td>\n",
              "      <td>634.375000</td>\n",
              "      <td>76.45975</td>\n",
              "      <td>13.41146</td>\n",
              "      <td>16.13136</td>\n",
              "      <td>15.56713</td>\n",
              "      <td>15.05353</td>\n",
              "      <td>37.22740</td>\n",
              "      <td>47.52422</td>\n",
              "      <td>31.11716</td>\n",
              "      <td>1.681353</td>\n",
              "      <td>419.5747</td>\n",
              "      <td>NaN</td>\n",
              "      <td>461.8781</td>\n",
              "      <td>466.3284</td>\n",
              "      <td>2.565284</td>\n",
              "      <td>665.3993</td>\n",
              "      <td>398.9862</td>\n",
              "      <td>880.0001</td>\n",
              "      <td>498.8926</td>\n",
              "      <td>975.9409</td>\n",
              "      <td>627.6740</td>\n",
              "      <td>741.7151</td>\n",
              "      <td>848.0708</td>\n",
              "      <td>429.0377</td>\n",
              "      <td>785.1935</td>\n",
              "      <td>684.9443</td>\n",
              "      <td>594.4445</td>\n",
              "      <td>682.8125</td>\n",
              "      <td>680.4416</td>\n",
              "      <td>433.7037</td>\n",
              "      <td>171.9375</td>\n",
              "      <td>341.9039</td>\n",
              "      <td>195.0655</td>\n",
              "      <td>90.32386</td>\n",
              "      <td>40.36458</td>\n",
              "      <td>31.51042</td>\n",
              "      <td>70.57291</td>\n",
              "      <td>30.989580</td>\n",
              "      <td>31.770832</td>\n",
              "      <td>41.92708</td>\n",
              "      <td>39.641200</td>\n",
              "      <td>65.68287</td>\n",
              "      <td>50.92593</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>157.9861</td>\n",
              "      <td>67.70834</td>\n",
              "      <td>243.0556</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2018-04-01 00:01:00</td>\n",
              "      <td>2.465394</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.310760</td>\n",
              "      <td>634.375000</td>\n",
              "      <td>76.45975</td>\n",
              "      <td>13.41146</td>\n",
              "      <td>16.13136</td>\n",
              "      <td>15.56713</td>\n",
              "      <td>15.05353</td>\n",
              "      <td>37.22740</td>\n",
              "      <td>47.52422</td>\n",
              "      <td>31.11716</td>\n",
              "      <td>1.681353</td>\n",
              "      <td>419.5747</td>\n",
              "      <td>NaN</td>\n",
              "      <td>461.8781</td>\n",
              "      <td>466.3284</td>\n",
              "      <td>2.565284</td>\n",
              "      <td>665.3993</td>\n",
              "      <td>398.9862</td>\n",
              "      <td>880.0001</td>\n",
              "      <td>498.8926</td>\n",
              "      <td>975.9409</td>\n",
              "      <td>627.6740</td>\n",
              "      <td>741.7151</td>\n",
              "      <td>848.0708</td>\n",
              "      <td>429.0377</td>\n",
              "      <td>785.1935</td>\n",
              "      <td>684.9443</td>\n",
              "      <td>594.4445</td>\n",
              "      <td>682.8125</td>\n",
              "      <td>680.4416</td>\n",
              "      <td>433.7037</td>\n",
              "      <td>171.9375</td>\n",
              "      <td>341.9039</td>\n",
              "      <td>195.0655</td>\n",
              "      <td>90.32386</td>\n",
              "      <td>40.36458</td>\n",
              "      <td>31.51042</td>\n",
              "      <td>70.57291</td>\n",
              "      <td>30.989580</td>\n",
              "      <td>31.770832</td>\n",
              "      <td>41.92708</td>\n",
              "      <td>39.641200</td>\n",
              "      <td>65.68287</td>\n",
              "      <td>50.92593</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>157.9861</td>\n",
              "      <td>67.70834</td>\n",
              "      <td>243.0556</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2018-04-01 00:02:00</td>\n",
              "      <td>2.444734</td>\n",
              "      <td>47.35243</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.397570</td>\n",
              "      <td>638.888900</td>\n",
              "      <td>73.54598</td>\n",
              "      <td>13.32465</td>\n",
              "      <td>16.03733</td>\n",
              "      <td>15.61777</td>\n",
              "      <td>15.01013</td>\n",
              "      <td>37.86777</td>\n",
              "      <td>48.17723</td>\n",
              "      <td>32.08894</td>\n",
              "      <td>1.708474</td>\n",
              "      <td>420.8480</td>\n",
              "      <td>NaN</td>\n",
              "      <td>462.7798</td>\n",
              "      <td>459.6364</td>\n",
              "      <td>2.500062</td>\n",
              "      <td>666.2234</td>\n",
              "      <td>399.9418</td>\n",
              "      <td>880.4237</td>\n",
              "      <td>501.3617</td>\n",
              "      <td>982.7342</td>\n",
              "      <td>631.1326</td>\n",
              "      <td>740.8031</td>\n",
              "      <td>849.8997</td>\n",
              "      <td>454.2390</td>\n",
              "      <td>778.5734</td>\n",
              "      <td>715.6266</td>\n",
              "      <td>661.5740</td>\n",
              "      <td>721.8750</td>\n",
              "      <td>694.7721</td>\n",
              "      <td>441.2635</td>\n",
              "      <td>169.9820</td>\n",
              "      <td>343.1955</td>\n",
              "      <td>200.9694</td>\n",
              "      <td>93.90508</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>31.25000</td>\n",
              "      <td>69.53125</td>\n",
              "      <td>30.468750</td>\n",
              "      <td>31.770830</td>\n",
              "      <td>41.66666</td>\n",
              "      <td>39.351852</td>\n",
              "      <td>65.39352</td>\n",
              "      <td>51.21528</td>\n",
              "      <td>38.194443</td>\n",
              "      <td>155.9606</td>\n",
              "      <td>67.12963</td>\n",
              "      <td>241.3194</td>\n",
              "      <td>203.7037</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2018-04-01 00:03:00</td>\n",
              "      <td>2.460474</td>\n",
              "      <td>47.09201</td>\n",
              "      <td>53.168400</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>628.125000</td>\n",
              "      <td>76.98898</td>\n",
              "      <td>13.31742</td>\n",
              "      <td>16.24711</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.08247</td>\n",
              "      <td>38.57977</td>\n",
              "      <td>48.65607</td>\n",
              "      <td>31.67221</td>\n",
              "      <td>1.579427</td>\n",
              "      <td>420.7494</td>\n",
              "      <td>NaN</td>\n",
              "      <td>462.8980</td>\n",
              "      <td>460.8858</td>\n",
              "      <td>2.509521</td>\n",
              "      <td>666.0114</td>\n",
              "      <td>399.1046</td>\n",
              "      <td>878.8917</td>\n",
              "      <td>499.0430</td>\n",
              "      <td>977.7520</td>\n",
              "      <td>625.4076</td>\n",
              "      <td>739.2722</td>\n",
              "      <td>847.7579</td>\n",
              "      <td>474.8731</td>\n",
              "      <td>779.5091</td>\n",
              "      <td>690.4011</td>\n",
              "      <td>686.1111</td>\n",
              "      <td>754.6875</td>\n",
              "      <td>683.3831</td>\n",
              "      <td>446.2493</td>\n",
              "      <td>166.4987</td>\n",
              "      <td>343.9586</td>\n",
              "      <td>193.1689</td>\n",
              "      <td>101.04060</td>\n",
              "      <td>41.92708</td>\n",
              "      <td>31.51042</td>\n",
              "      <td>72.13541</td>\n",
              "      <td>30.468750</td>\n",
              "      <td>31.510420</td>\n",
              "      <td>40.88541</td>\n",
              "      <td>39.062500</td>\n",
              "      <td>64.81481</td>\n",
              "      <td>51.21528</td>\n",
              "      <td>38.194440</td>\n",
              "      <td>155.9606</td>\n",
              "      <td>66.84028</td>\n",
              "      <td>240.4514</td>\n",
              "      <td>203.1250</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2018-04-01 00:04:00</td>\n",
              "      <td>2.445718</td>\n",
              "      <td>47.13541</td>\n",
              "      <td>53.211800</td>\n",
              "      <td>46.397568</td>\n",
              "      <td>636.458300</td>\n",
              "      <td>76.58897</td>\n",
              "      <td>13.35359</td>\n",
              "      <td>16.21094</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.08247</td>\n",
              "      <td>39.48939</td>\n",
              "      <td>49.06298</td>\n",
              "      <td>31.95202</td>\n",
              "      <td>1.683831</td>\n",
              "      <td>419.8926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>461.4906</td>\n",
              "      <td>468.2206</td>\n",
              "      <td>2.604785</td>\n",
              "      <td>663.2111</td>\n",
              "      <td>400.5426</td>\n",
              "      <td>882.5874</td>\n",
              "      <td>498.5383</td>\n",
              "      <td>979.5755</td>\n",
              "      <td>627.1830</td>\n",
              "      <td>737.6033</td>\n",
              "      <td>846.9182</td>\n",
              "      <td>408.8159</td>\n",
              "      <td>785.2307</td>\n",
              "      <td>704.6937</td>\n",
              "      <td>631.4814</td>\n",
              "      <td>766.1458</td>\n",
              "      <td>702.4431</td>\n",
              "      <td>433.9081</td>\n",
              "      <td>164.7498</td>\n",
              "      <td>339.9630</td>\n",
              "      <td>193.8770</td>\n",
              "      <td>101.70380</td>\n",
              "      <td>42.70833</td>\n",
              "      <td>31.51042</td>\n",
              "      <td>76.82291</td>\n",
              "      <td>30.989580</td>\n",
              "      <td>31.510420</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>65.10416</td>\n",
              "      <td>51.79398</td>\n",
              "      <td>38.773150</td>\n",
              "      <td>158.2755</td>\n",
              "      <td>66.55093</td>\n",
              "      <td>242.1875</td>\n",
              "      <td>201.3889</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220315</th>\n",
              "      <td>220315</td>\n",
              "      <td>2018-08-31 23:55:00</td>\n",
              "      <td>2.407350</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>634.722229</td>\n",
              "      <td>64.59095</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>43.17085</td>\n",
              "      <td>54.16052</td>\n",
              "      <td>38.05424</td>\n",
              "      <td>13.265320</td>\n",
              "      <td>420.7993</td>\n",
              "      <td>NaN</td>\n",
              "      <td>463.2318</td>\n",
              "      <td>458.3615</td>\n",
              "      <td>2.499117</td>\n",
              "      <td>676.6655</td>\n",
              "      <td>405.7680</td>\n",
              "      <td>894.5920</td>\n",
              "      <td>543.5801</td>\n",
              "      <td>1109.5010</td>\n",
              "      <td>611.1745</td>\n",
              "      <td>700.5885</td>\n",
              "      <td>796.5964</td>\n",
              "      <td>692.1138</td>\n",
              "      <td>779.2067</td>\n",
              "      <td>485.0358</td>\n",
              "      <td>691.6666</td>\n",
              "      <td>974.9999</td>\n",
              "      <td>927.6135</td>\n",
              "      <td>477.3156</td>\n",
              "      <td>266.0334</td>\n",
              "      <td>578.5221</td>\n",
              "      <td>817.5707</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>47.13541</td>\n",
              "      <td>29.16667</td>\n",
              "      <td>71.61458</td>\n",
              "      <td>30.468750</td>\n",
              "      <td>30.208330</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>68.287030</td>\n",
              "      <td>52.37268</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>41.087960</td>\n",
              "      <td>212.3843</td>\n",
              "      <td>153.64580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220316</th>\n",
              "      <td>220316</td>\n",
              "      <td>2018-08-31 23:56:00</td>\n",
              "      <td>2.400463</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.564240</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>630.902771</td>\n",
              "      <td>65.83363</td>\n",
              "      <td>15.15480</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>43.21038</td>\n",
              "      <td>54.52602</td>\n",
              "      <td>38.53485</td>\n",
              "      <td>13.242270</td>\n",
              "      <td>422.1567</td>\n",
              "      <td>NaN</td>\n",
              "      <td>463.1928</td>\n",
              "      <td>468.4388</td>\n",
              "      <td>2.618476</td>\n",
              "      <td>676.6547</td>\n",
              "      <td>406.2575</td>\n",
              "      <td>895.5599</td>\n",
              "      <td>541.7014</td>\n",
              "      <td>1106.3710</td>\n",
              "      <td>609.4917</td>\n",
              "      <td>698.4915</td>\n",
              "      <td>800.1906</td>\n",
              "      <td>697.8002</td>\n",
              "      <td>797.5571</td>\n",
              "      <td>510.9510</td>\n",
              "      <td>672.2222</td>\n",
              "      <td>927.0833</td>\n",
              "      <td>907.9463</td>\n",
              "      <td>487.8679</td>\n",
              "      <td>262.2222</td>\n",
              "      <td>568.1035</td>\n",
              "      <td>807.0151</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>46.87500</td>\n",
              "      <td>28.90625</td>\n",
              "      <td>73.17708</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>29.947920</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>66.840280</td>\n",
              "      <td>50.63657</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>213.8310</td>\n",
              "      <td>156.25000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220317</th>\n",
              "      <td>220317</td>\n",
              "      <td>2018-08-31 23:57:00</td>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>625.925903</td>\n",
              "      <td>67.29445</td>\n",
              "      <td>15.08970</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>43.12836</td>\n",
              "      <td>55.11779</td>\n",
              "      <td>38.52678</td>\n",
              "      <td>13.188660</td>\n",
              "      <td>420.2166</td>\n",
              "      <td>NaN</td>\n",
              "      <td>462.4065</td>\n",
              "      <td>468.6293</td>\n",
              "      <td>2.620500</td>\n",
              "      <td>677.3162</td>\n",
              "      <td>407.1144</td>\n",
              "      <td>892.2204</td>\n",
              "      <td>542.8578</td>\n",
              "      <td>1106.6980</td>\n",
              "      <td>610.9940</td>\n",
              "      <td>703.1645</td>\n",
              "      <td>800.3767</td>\n",
              "      <td>704.6601</td>\n",
              "      <td>799.3120</td>\n",
              "      <td>492.7720</td>\n",
              "      <td>689.3519</td>\n",
              "      <td>924.4791</td>\n",
              "      <td>926.8102</td>\n",
              "      <td>494.1249</td>\n",
              "      <td>260.8372</td>\n",
              "      <td>553.8872</td>\n",
              "      <td>805.5605</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>46.09375</td>\n",
              "      <td>28.64583</td>\n",
              "      <td>77.08333</td>\n",
              "      <td>29.947920</td>\n",
              "      <td>30.208330</td>\n",
              "      <td>39.06250</td>\n",
              "      <td>65.393520</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>217.3032</td>\n",
              "      <td>155.38190</td>\n",
              "      <td>NaN</td>\n",
              "      <td>232.0602</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220318</th>\n",
              "      <td>220318</td>\n",
              "      <td>2018-08-31 23:58:00</td>\n",
              "      <td>2.406366</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>635.648100</td>\n",
              "      <td>65.09175</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.56539</td>\n",
              "      <td>15.74074</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>42.35746</td>\n",
              "      <td>55.99321</td>\n",
              "      <td>38.89159</td>\n",
              "      <td>13.173460</td>\n",
              "      <td>420.5700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>457.0362</td>\n",
              "      <td>459.7941</td>\n",
              "      <td>2.514596</td>\n",
              "      <td>672.6165</td>\n",
              "      <td>404.3277</td>\n",
              "      <td>887.9969</td>\n",
              "      <td>539.3630</td>\n",
              "      <td>1103.9550</td>\n",
              "      <td>605.7183</td>\n",
              "      <td>697.3713</td>\n",
              "      <td>793.7070</td>\n",
              "      <td>706.9692</td>\n",
              "      <td>793.0610</td>\n",
              "      <td>490.2170</td>\n",
              "      <td>687.0370</td>\n",
              "      <td>931.7708</td>\n",
              "      <td>915.4362</td>\n",
              "      <td>484.1161</td>\n",
              "      <td>261.3184</td>\n",
              "      <td>559.4439</td>\n",
              "      <td>807.0808</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>45.83333</td>\n",
              "      <td>28.38542</td>\n",
              "      <td>78.64583</td>\n",
              "      <td>29.947916</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>40.62500</td>\n",
              "      <td>64.236110</td>\n",
              "      <td>47.74306</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>40.509258</td>\n",
              "      <td>222.5116</td>\n",
              "      <td>153.93520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220319</th>\n",
              "      <td>220319</td>\n",
              "      <td>2018-08-31 23:59:00</td>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.69965</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>639.814800</td>\n",
              "      <td>65.45634</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.01013</td>\n",
              "      <td>42.62814</td>\n",
              "      <td>56.49642</td>\n",
              "      <td>39.40957</td>\n",
              "      <td>13.125930</td>\n",
              "      <td>421.2080</td>\n",
              "      <td>NaN</td>\n",
              "      <td>468.9915</td>\n",
              "      <td>456.5726</td>\n",
              "      <td>2.487299</td>\n",
              "      <td>676.5834</td>\n",
              "      <td>405.6293</td>\n",
              "      <td>897.8508</td>\n",
              "      <td>542.0950</td>\n",
              "      <td>1108.8270</td>\n",
              "      <td>608.5364</td>\n",
              "      <td>698.0792</td>\n",
              "      <td>800.0387</td>\n",
              "      <td>703.6251</td>\n",
              "      <td>800.2143</td>\n",
              "      <td>496.4068</td>\n",
              "      <td>686.1111</td>\n",
              "      <td>917.7083</td>\n",
              "      <td>926.3979</td>\n",
              "      <td>489.0367</td>\n",
              "      <td>258.4387</td>\n",
              "      <td>558.0558</td>\n",
              "      <td>811.1204</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>45.31250</td>\n",
              "      <td>27.86458</td>\n",
              "      <td>77.86458</td>\n",
              "      <td>29.947916</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>62.789350</td>\n",
              "      <td>46.29630</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>40.219910</td>\n",
              "      <td>227.4306</td>\n",
              "      <td>150.46300</td>\n",
              "      <td>NaN</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>NORMAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>220320 rows × 55 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0            timestamp  ...  sensor_51  machine_status\n",
              "0                0  2018-04-01 00:00:00  ...   201.3889          NORMAL\n",
              "1                1  2018-04-01 00:01:00  ...   201.3889          NORMAL\n",
              "2                2  2018-04-01 00:02:00  ...   203.7037          NORMAL\n",
              "3                3  2018-04-01 00:03:00  ...   203.1250          NORMAL\n",
              "4                4  2018-04-01 00:04:00  ...   201.3889          NORMAL\n",
              "...            ...                  ...  ...        ...             ...\n",
              "220315      220315  2018-08-31 23:55:00  ...   231.1921          NORMAL\n",
              "220316      220316  2018-08-31 23:56:00  ...   231.1921          NORMAL\n",
              "220317      220317  2018-08-31 23:57:00  ...   232.0602          NORMAL\n",
              "220318      220318  2018-08-31 23:58:00  ...   234.0856          NORMAL\n",
              "220319      220319  2018-08-31 23:59:00  ...   234.0856          NORMAL\n",
              "\n",
              "[220320 rows x 55 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDdNXL-c4_CH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def missing_data_treatment(data):\n",
        "  for i in data.columns:\n",
        "    if data[i].dtype == 'object':\n",
        "      data[i] = data[i].fillna(data[i].mode().iloc[0])\n",
        "    if (data[i].dtype == 'int' or data[i].dtype == 'float'):\n",
        "      data[i] = data[i].fillna(np.mean(data[i]))\n",
        "\n",
        "def label_encoding(data, encoder):\n",
        "  for i in data.columns:\n",
        "    if (data[i].dtype == 'object'):\n",
        "      data[i] = encoder.fit_transform(data[i].astype('str'))\n",
        "      data[i] = data[i].astype('object')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_vDJn1fJVOx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9IIsZN27w_q",
        "colab_type": "code",
        "outputId": "e0d7c0a9-6996-4bc6-9d52-4f5d1e4191d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        }
      },
      "source": [
        "df = df.drop(columns=['sensor_15'])\n",
        "\n",
        "missing_data_treatment(df)\n",
        "number = LabelEncoder()\n",
        "label_encoding(df, number)\n",
        "\n",
        "train, test = train_test_split(df, shuffle=False)\n",
        "\n",
        "test"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sensor_00</th>\n",
              "      <th>sensor_01</th>\n",
              "      <th>sensor_02</th>\n",
              "      <th>sensor_03</th>\n",
              "      <th>sensor_04</th>\n",
              "      <th>sensor_05</th>\n",
              "      <th>sensor_06</th>\n",
              "      <th>sensor_07</th>\n",
              "      <th>sensor_08</th>\n",
              "      <th>sensor_09</th>\n",
              "      <th>sensor_10</th>\n",
              "      <th>sensor_11</th>\n",
              "      <th>sensor_12</th>\n",
              "      <th>sensor_13</th>\n",
              "      <th>sensor_14</th>\n",
              "      <th>sensor_16</th>\n",
              "      <th>sensor_17</th>\n",
              "      <th>sensor_18</th>\n",
              "      <th>sensor_19</th>\n",
              "      <th>sensor_20</th>\n",
              "      <th>sensor_21</th>\n",
              "      <th>sensor_22</th>\n",
              "      <th>sensor_23</th>\n",
              "      <th>sensor_24</th>\n",
              "      <th>sensor_25</th>\n",
              "      <th>sensor_26</th>\n",
              "      <th>sensor_27</th>\n",
              "      <th>sensor_28</th>\n",
              "      <th>sensor_29</th>\n",
              "      <th>sensor_30</th>\n",
              "      <th>sensor_31</th>\n",
              "      <th>sensor_32</th>\n",
              "      <th>sensor_33</th>\n",
              "      <th>sensor_34</th>\n",
              "      <th>sensor_35</th>\n",
              "      <th>sensor_36</th>\n",
              "      <th>sensor_37</th>\n",
              "      <th>sensor_38</th>\n",
              "      <th>sensor_39</th>\n",
              "      <th>sensor_40</th>\n",
              "      <th>sensor_41</th>\n",
              "      <th>sensor_42</th>\n",
              "      <th>sensor_43</th>\n",
              "      <th>sensor_44</th>\n",
              "      <th>sensor_45</th>\n",
              "      <th>sensor_46</th>\n",
              "      <th>sensor_47</th>\n",
              "      <th>sensor_48</th>\n",
              "      <th>sensor_49</th>\n",
              "      <th>sensor_50</th>\n",
              "      <th>sensor_51</th>\n",
              "      <th>machine_status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165240</th>\n",
              "      <td>165240</td>\n",
              "      <td>165240</td>\n",
              "      <td>2.453588</td>\n",
              "      <td>45.876740</td>\n",
              "      <td>53.689240</td>\n",
              "      <td>45.138885</td>\n",
              "      <td>637.036987</td>\n",
              "      <td>64.82624</td>\n",
              "      <td>14.57610</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.70457</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>44.54719</td>\n",
              "      <td>51.14783</td>\n",
              "      <td>32.63393</td>\n",
              "      <td>19.29945</td>\n",
              "      <td>421.2889</td>\n",
              "      <td>464.5879</td>\n",
              "      <td>453.7494</td>\n",
              "      <td>2.459248</td>\n",
              "      <td>667.3094</td>\n",
              "      <td>400.7867</td>\n",
              "      <td>882.7717</td>\n",
              "      <td>535.7959</td>\n",
              "      <td>1095.641</td>\n",
              "      <td>627.8105</td>\n",
              "      <td>741.7908</td>\n",
              "      <td>983.1227</td>\n",
              "      <td>517.4292</td>\n",
              "      <td>1051.0540</td>\n",
              "      <td>598.4416</td>\n",
              "      <td>719.9074</td>\n",
              "      <td>985.4166</td>\n",
              "      <td>1009.5890</td>\n",
              "      <td>543.2834</td>\n",
              "      <td>370.6706</td>\n",
              "      <td>548.2872</td>\n",
              "      <td>836.0478</td>\n",
              "      <td>51.24624</td>\n",
              "      <td>52.34375</td>\n",
              "      <td>35.15625</td>\n",
              "      <td>100.26040</td>\n",
              "      <td>35.416660</td>\n",
              "      <td>35.156250</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>46.29630</td>\n",
              "      <td>40.219906</td>\n",
              "      <td>54.97685</td>\n",
              "      <td>43.692130</td>\n",
              "      <td>222.5116</td>\n",
              "      <td>53.240740</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>175.6366</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165241</th>\n",
              "      <td>165241</td>\n",
              "      <td>165241</td>\n",
              "      <td>2.453588</td>\n",
              "      <td>45.876740</td>\n",
              "      <td>53.689240</td>\n",
              "      <td>45.138885</td>\n",
              "      <td>637.036987</td>\n",
              "      <td>64.82624</td>\n",
              "      <td>14.57610</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.70457</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>44.54719</td>\n",
              "      <td>51.14783</td>\n",
              "      <td>32.63393</td>\n",
              "      <td>19.29945</td>\n",
              "      <td>421.2889</td>\n",
              "      <td>464.5879</td>\n",
              "      <td>453.7494</td>\n",
              "      <td>2.459248</td>\n",
              "      <td>667.3094</td>\n",
              "      <td>400.7867</td>\n",
              "      <td>882.7717</td>\n",
              "      <td>535.7959</td>\n",
              "      <td>1095.641</td>\n",
              "      <td>627.8105</td>\n",
              "      <td>741.7908</td>\n",
              "      <td>983.1227</td>\n",
              "      <td>517.4292</td>\n",
              "      <td>1051.0540</td>\n",
              "      <td>598.4416</td>\n",
              "      <td>719.9074</td>\n",
              "      <td>985.4166</td>\n",
              "      <td>1009.5890</td>\n",
              "      <td>543.2834</td>\n",
              "      <td>370.6706</td>\n",
              "      <td>548.2872</td>\n",
              "      <td>836.0478</td>\n",
              "      <td>51.24624</td>\n",
              "      <td>52.34375</td>\n",
              "      <td>35.15625</td>\n",
              "      <td>100.26040</td>\n",
              "      <td>35.416660</td>\n",
              "      <td>35.156250</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>46.29630</td>\n",
              "      <td>40.219906</td>\n",
              "      <td>54.97685</td>\n",
              "      <td>43.692130</td>\n",
              "      <td>222.5116</td>\n",
              "      <td>53.240740</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>175.6366</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165242</th>\n",
              "      <td>165242</td>\n",
              "      <td>165242</td>\n",
              "      <td>2.449653</td>\n",
              "      <td>45.963540</td>\n",
              "      <td>53.645830</td>\n",
              "      <td>45.138885</td>\n",
              "      <td>635.879639</td>\n",
              "      <td>65.98254</td>\n",
              "      <td>14.60503</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.61777</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>44.26668</td>\n",
              "      <td>52.62779</td>\n",
              "      <td>32.26524</td>\n",
              "      <td>19.32389</td>\n",
              "      <td>419.8232</td>\n",
              "      <td>458.6252</td>\n",
              "      <td>466.0694</td>\n",
              "      <td>2.588427</td>\n",
              "      <td>665.1129</td>\n",
              "      <td>399.2256</td>\n",
              "      <td>879.5967</td>\n",
              "      <td>534.7852</td>\n",
              "      <td>1089.110</td>\n",
              "      <td>630.3295</td>\n",
              "      <td>741.7555</td>\n",
              "      <td>981.1262</td>\n",
              "      <td>496.7821</td>\n",
              "      <td>1061.8190</td>\n",
              "      <td>563.2458</td>\n",
              "      <td>706.4814</td>\n",
              "      <td>1062.5000</td>\n",
              "      <td>1023.0380</td>\n",
              "      <td>577.7612</td>\n",
              "      <td>364.0239</td>\n",
              "      <td>540.9376</td>\n",
              "      <td>833.4713</td>\n",
              "      <td>47.85880</td>\n",
              "      <td>51.30208</td>\n",
              "      <td>34.89583</td>\n",
              "      <td>97.39583</td>\n",
              "      <td>35.416660</td>\n",
              "      <td>35.416660</td>\n",
              "      <td>50.78125</td>\n",
              "      <td>45.13889</td>\n",
              "      <td>40.219906</td>\n",
              "      <td>57.00232</td>\n",
              "      <td>43.692130</td>\n",
              "      <td>224.2477</td>\n",
              "      <td>53.530090</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>175.3472</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165243</th>\n",
              "      <td>165243</td>\n",
              "      <td>165243</td>\n",
              "      <td>2.459491</td>\n",
              "      <td>45.876740</td>\n",
              "      <td>53.645832</td>\n",
              "      <td>45.138885</td>\n",
              "      <td>633.217590</td>\n",
              "      <td>67.68879</td>\n",
              "      <td>14.53993</td>\n",
              "      <td>16.60880</td>\n",
              "      <td>15.61777</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>44.00895</td>\n",
              "      <td>52.73262</td>\n",
              "      <td>32.25240</td>\n",
              "      <td>18.52543</td>\n",
              "      <td>420.8510</td>\n",
              "      <td>462.5743</td>\n",
              "      <td>466.6902</td>\n",
              "      <td>2.565156</td>\n",
              "      <td>665.3815</td>\n",
              "      <td>397.6859</td>\n",
              "      <td>876.1518</td>\n",
              "      <td>534.7910</td>\n",
              "      <td>1088.459</td>\n",
              "      <td>624.3346</td>\n",
              "      <td>739.8666</td>\n",
              "      <td>980.4238</td>\n",
              "      <td>488.4244</td>\n",
              "      <td>1051.0550</td>\n",
              "      <td>553.6876</td>\n",
              "      <td>690.7407</td>\n",
              "      <td>1029.1670</td>\n",
              "      <td>956.5541</td>\n",
              "      <td>539.4008</td>\n",
              "      <td>361.5701</td>\n",
              "      <td>545.2599</td>\n",
              "      <td>838.9528</td>\n",
              "      <td>41.62543</td>\n",
              "      <td>51.04166</td>\n",
              "      <td>34.11458</td>\n",
              "      <td>95.05208</td>\n",
              "      <td>35.156250</td>\n",
              "      <td>35.156250</td>\n",
              "      <td>50.00000</td>\n",
              "      <td>44.56018</td>\n",
              "      <td>40.219910</td>\n",
              "      <td>58.15972</td>\n",
              "      <td>43.981480</td>\n",
              "      <td>225.6944</td>\n",
              "      <td>53.819440</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>173.9005</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165244</th>\n",
              "      <td>165244</td>\n",
              "      <td>165244</td>\n",
              "      <td>2.449653</td>\n",
              "      <td>45.876736</td>\n",
              "      <td>53.645830</td>\n",
              "      <td>45.138885</td>\n",
              "      <td>632.407349</td>\n",
              "      <td>66.92718</td>\n",
              "      <td>14.60503</td>\n",
              "      <td>16.60880</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>44.43157</td>\n",
              "      <td>52.87685</td>\n",
              "      <td>32.08264</td>\n",
              "      <td>18.96363</td>\n",
              "      <td>420.0955</td>\n",
              "      <td>462.8652</td>\n",
              "      <td>467.5453</td>\n",
              "      <td>2.589695</td>\n",
              "      <td>663.7889</td>\n",
              "      <td>399.1443</td>\n",
              "      <td>880.2036</td>\n",
              "      <td>533.3046</td>\n",
              "      <td>1088.436</td>\n",
              "      <td>627.7715</td>\n",
              "      <td>739.6794</td>\n",
              "      <td>981.4586</td>\n",
              "      <td>471.1146</td>\n",
              "      <td>1060.1300</td>\n",
              "      <td>545.2603</td>\n",
              "      <td>655.0926</td>\n",
              "      <td>947.3958</td>\n",
              "      <td>1016.2690</td>\n",
              "      <td>555.5678</td>\n",
              "      <td>361.7527</td>\n",
              "      <td>537.9611</td>\n",
              "      <td>847.1089</td>\n",
              "      <td>60.82851</td>\n",
              "      <td>50.78125</td>\n",
              "      <td>33.85416</td>\n",
              "      <td>92.70833</td>\n",
              "      <td>35.156250</td>\n",
              "      <td>35.156250</td>\n",
              "      <td>49.47916</td>\n",
              "      <td>43.69213</td>\n",
              "      <td>40.509258</td>\n",
              "      <td>59.31713</td>\n",
              "      <td>43.981480</td>\n",
              "      <td>225.6944</td>\n",
              "      <td>53.819443</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>172.7431</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220315</th>\n",
              "      <td>220315</td>\n",
              "      <td>220315</td>\n",
              "      <td>2.407350</td>\n",
              "      <td>47.699650</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>634.722229</td>\n",
              "      <td>64.59095</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.16204</td>\n",
              "      <td>43.17085</td>\n",
              "      <td>54.16052</td>\n",
              "      <td>38.05424</td>\n",
              "      <td>13.26532</td>\n",
              "      <td>420.7993</td>\n",
              "      <td>463.2318</td>\n",
              "      <td>458.3615</td>\n",
              "      <td>2.499117</td>\n",
              "      <td>676.6655</td>\n",
              "      <td>405.7680</td>\n",
              "      <td>894.5920</td>\n",
              "      <td>543.5801</td>\n",
              "      <td>1109.501</td>\n",
              "      <td>611.1745</td>\n",
              "      <td>700.5885</td>\n",
              "      <td>796.5964</td>\n",
              "      <td>692.1138</td>\n",
              "      <td>779.2067</td>\n",
              "      <td>485.0358</td>\n",
              "      <td>691.6666</td>\n",
              "      <td>974.9999</td>\n",
              "      <td>927.6135</td>\n",
              "      <td>477.3156</td>\n",
              "      <td>266.0334</td>\n",
              "      <td>578.5221</td>\n",
              "      <td>817.5707</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>47.13541</td>\n",
              "      <td>29.16667</td>\n",
              "      <td>71.61458</td>\n",
              "      <td>30.468750</td>\n",
              "      <td>30.208330</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>68.28703</td>\n",
              "      <td>52.372680</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>41.087960</td>\n",
              "      <td>212.3843</td>\n",
              "      <td>153.645800</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220316</th>\n",
              "      <td>220316</td>\n",
              "      <td>220316</td>\n",
              "      <td>2.400463</td>\n",
              "      <td>47.699650</td>\n",
              "      <td>50.564240</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>630.902771</td>\n",
              "      <td>65.83363</td>\n",
              "      <td>15.15480</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>43.21038</td>\n",
              "      <td>54.52602</td>\n",
              "      <td>38.53485</td>\n",
              "      <td>13.24227</td>\n",
              "      <td>422.1567</td>\n",
              "      <td>463.1928</td>\n",
              "      <td>468.4388</td>\n",
              "      <td>2.618476</td>\n",
              "      <td>676.6547</td>\n",
              "      <td>406.2575</td>\n",
              "      <td>895.5599</td>\n",
              "      <td>541.7014</td>\n",
              "      <td>1106.371</td>\n",
              "      <td>609.4917</td>\n",
              "      <td>698.4915</td>\n",
              "      <td>800.1906</td>\n",
              "      <td>697.8002</td>\n",
              "      <td>797.5571</td>\n",
              "      <td>510.9510</td>\n",
              "      <td>672.2222</td>\n",
              "      <td>927.0833</td>\n",
              "      <td>907.9463</td>\n",
              "      <td>487.8679</td>\n",
              "      <td>262.2222</td>\n",
              "      <td>568.1035</td>\n",
              "      <td>807.0151</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>46.87500</td>\n",
              "      <td>28.90625</td>\n",
              "      <td>73.17708</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>29.947920</td>\n",
              "      <td>38.28125</td>\n",
              "      <td>66.84028</td>\n",
              "      <td>50.636570</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>213.8310</td>\n",
              "      <td>156.250000</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>231.1921</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220317</th>\n",
              "      <td>220317</td>\n",
              "      <td>220317</td>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.699650</td>\n",
              "      <td>50.520830</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>625.925903</td>\n",
              "      <td>67.29445</td>\n",
              "      <td>15.08970</td>\n",
              "      <td>16.70284</td>\n",
              "      <td>15.69734</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>43.12836</td>\n",
              "      <td>55.11779</td>\n",
              "      <td>38.52678</td>\n",
              "      <td>13.18866</td>\n",
              "      <td>420.2166</td>\n",
              "      <td>462.4065</td>\n",
              "      <td>468.6293</td>\n",
              "      <td>2.620500</td>\n",
              "      <td>677.3162</td>\n",
              "      <td>407.1144</td>\n",
              "      <td>892.2204</td>\n",
              "      <td>542.8578</td>\n",
              "      <td>1106.698</td>\n",
              "      <td>610.9940</td>\n",
              "      <td>703.1645</td>\n",
              "      <td>800.3767</td>\n",
              "      <td>704.6601</td>\n",
              "      <td>799.3120</td>\n",
              "      <td>492.7720</td>\n",
              "      <td>689.3519</td>\n",
              "      <td>924.4791</td>\n",
              "      <td>926.8102</td>\n",
              "      <td>494.1249</td>\n",
              "      <td>260.8372</td>\n",
              "      <td>553.8872</td>\n",
              "      <td>805.5605</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>46.09375</td>\n",
              "      <td>28.64583</td>\n",
              "      <td>77.08333</td>\n",
              "      <td>29.947920</td>\n",
              "      <td>30.208330</td>\n",
              "      <td>39.06250</td>\n",
              "      <td>65.39352</td>\n",
              "      <td>48.900460</td>\n",
              "      <td>48.03241</td>\n",
              "      <td>40.798610</td>\n",
              "      <td>217.3032</td>\n",
              "      <td>155.381900</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>232.0602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220318</th>\n",
              "      <td>220318</td>\n",
              "      <td>220318</td>\n",
              "      <td>2.406366</td>\n",
              "      <td>47.699650</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>635.648100</td>\n",
              "      <td>65.09175</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.56539</td>\n",
              "      <td>15.74074</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>42.35746</td>\n",
              "      <td>55.99321</td>\n",
              "      <td>38.89159</td>\n",
              "      <td>13.17346</td>\n",
              "      <td>420.5700</td>\n",
              "      <td>457.0362</td>\n",
              "      <td>459.7941</td>\n",
              "      <td>2.514596</td>\n",
              "      <td>672.6165</td>\n",
              "      <td>404.3277</td>\n",
              "      <td>887.9969</td>\n",
              "      <td>539.3630</td>\n",
              "      <td>1103.955</td>\n",
              "      <td>605.7183</td>\n",
              "      <td>697.3713</td>\n",
              "      <td>793.7070</td>\n",
              "      <td>706.9692</td>\n",
              "      <td>793.0610</td>\n",
              "      <td>490.2170</td>\n",
              "      <td>687.0370</td>\n",
              "      <td>931.7708</td>\n",
              "      <td>915.4362</td>\n",
              "      <td>484.1161</td>\n",
              "      <td>261.3184</td>\n",
              "      <td>559.4439</td>\n",
              "      <td>807.0808</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>45.83333</td>\n",
              "      <td>28.38542</td>\n",
              "      <td>78.64583</td>\n",
              "      <td>29.947916</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>40.62500</td>\n",
              "      <td>64.23611</td>\n",
              "      <td>47.743060</td>\n",
              "      <td>48.32176</td>\n",
              "      <td>40.509258</td>\n",
              "      <td>222.5116</td>\n",
              "      <td>153.935200</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220319</th>\n",
              "      <td>220319</td>\n",
              "      <td>220319</td>\n",
              "      <td>2.396528</td>\n",
              "      <td>47.699650</td>\n",
              "      <td>50.520832</td>\n",
              "      <td>43.142361</td>\n",
              "      <td>639.814800</td>\n",
              "      <td>65.45634</td>\n",
              "      <td>15.11863</td>\n",
              "      <td>16.65220</td>\n",
              "      <td>15.65393</td>\n",
              "      <td>15.01013</td>\n",
              "      <td>42.62814</td>\n",
              "      <td>56.49642</td>\n",
              "      <td>39.40957</td>\n",
              "      <td>13.12593</td>\n",
              "      <td>421.2080</td>\n",
              "      <td>468.9915</td>\n",
              "      <td>456.5726</td>\n",
              "      <td>2.487299</td>\n",
              "      <td>676.5834</td>\n",
              "      <td>405.6293</td>\n",
              "      <td>897.8508</td>\n",
              "      <td>542.0950</td>\n",
              "      <td>1108.827</td>\n",
              "      <td>608.5364</td>\n",
              "      <td>698.0792</td>\n",
              "      <td>800.0387</td>\n",
              "      <td>703.6251</td>\n",
              "      <td>800.2143</td>\n",
              "      <td>496.4068</td>\n",
              "      <td>686.1111</td>\n",
              "      <td>917.7083</td>\n",
              "      <td>926.3979</td>\n",
              "      <td>489.0367</td>\n",
              "      <td>258.4387</td>\n",
              "      <td>558.0558</td>\n",
              "      <td>811.1204</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>45.31250</td>\n",
              "      <td>27.86458</td>\n",
              "      <td>77.86458</td>\n",
              "      <td>29.947916</td>\n",
              "      <td>30.208332</td>\n",
              "      <td>41.40625</td>\n",
              "      <td>62.78935</td>\n",
              "      <td>46.296300</td>\n",
              "      <td>48.90046</td>\n",
              "      <td>40.219910</td>\n",
              "      <td>227.4306</td>\n",
              "      <td>150.463000</td>\n",
              "      <td>183.04926</td>\n",
              "      <td>234.0856</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>55080 rows × 54 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0 timestamp  sensor_00  ...  sensor_50  sensor_51  machine_status\n",
              "165240      165240    165240   2.453588  ...  183.04926   175.6366               1\n",
              "165241      165241    165241   2.453588  ...  183.04926   175.6366               1\n",
              "165242      165242    165242   2.449653  ...  183.04926   175.3472               1\n",
              "165243      165243    165243   2.459491  ...  183.04926   173.9005               1\n",
              "165244      165244    165244   2.449653  ...  183.04926   172.7431               1\n",
              "...            ...       ...        ...  ...        ...        ...             ...\n",
              "220315      220315    220315   2.407350  ...  183.04926   231.1921               1\n",
              "220316      220316    220316   2.400463  ...  183.04926   231.1921               1\n",
              "220317      220317    220317   2.396528  ...  183.04926   232.0602               1\n",
              "220318      220318    220318   2.406366  ...  183.04926   234.0856               1\n",
              "220319      220319    220319   2.396528  ...  183.04926   234.0856               1\n",
              "\n",
              "[55080 rows x 54 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYHF66LK7ong",
        "colab_type": "code",
        "outputId": "43b6245f-187e-404e-eff1-0d332a61140a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "plt.subplot()\n",
        "plt.plot( train.machine_status)\n",
        "plt.ylabel('sensor_13')\n",
        "plt.subplot()\n",
        "plt.plot(test.machine_status)\n",
        "plt.ylabel('sensor_13')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um7hvmwWgNLt",
        "colab_type": "text"
      },
      "source": [
        "# Functions for checking Covariate Shift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJpSK7CizxUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare_train_test_distribution(train, test, col, bins):  \n",
        "  N_points = 100000\n",
        "  n_bins = bins\n",
        "\n",
        "  x = train[col]\n",
        "  y = test[col]\n",
        "\n",
        "  fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "  # We can set the number of bins with the `bins` kwarg\n",
        "  axs[0].hist(x, bins=n_bins)\n",
        "  axs[1].hist(y, bins=n_bins)\n",
        "\n",
        "def concat(train_df, test_df, id_column, y):\n",
        "  train_df.drop(columns=[id_column, y], inplace=True)\n",
        "  test_df.drop(columns=[id_column, y], inplace=True)\n",
        "\n",
        "  train_df['is_test'] = 0\n",
        "  test_df['is_test'] = 1\n",
        "  df = pd.concat([train_df, test_df], axis = 0)\n",
        "  return df\n",
        "\n",
        "def shuffle_split(df):\n",
        "  y = df['is_test']\n",
        "  X = df.drop(columns=['is_test'])\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
        "  print('train2 shape:', X_train.shape, 'test2 shape:', X_test.shape)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "def test_shift(X_train, X_test, y_train, y_test):\n",
        "  rfc = RandomForestClassifier()\n",
        "  rfc.fit(X_train, y_train)\n",
        "  y_test_score = rfc.predict_proba(X_test)\n",
        "\n",
        "  print('AUC score: ', round(roc_auc_score(y_true=y_test, y_score=y_test_score[:,1]), 4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cr5_Dm4midz",
        "colab_type": "text"
      },
      "source": [
        "# Applying the functions to the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU8q8Z-K2-dr",
        "colab_type": "code",
        "outputId": "dc652e5b-f423-4a37-ae31-5d4ddb9be1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "train_c = train.copy()\n",
        "test_c = test.copy()\n",
        "\n",
        "compare_train_test_distribution(train_c, test_c, 'sensor_13', 5)\n",
        "\n",
        "concat_df = concat(train_c, test_c, 'Unnamed: 0', 'machine_status')\n",
        "param = shuffle_split(concat_df)\n",
        "\n",
        "test_shift(param[0], param[1], param[2], param[3])\n",
        "\n",
        "np.any(pd.isna(train))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train2 shape: (154224, 52) test2 shape: (66096, 52)\n",
            "AUC score:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ3k0xo0RycW",
        "colab_type": "text"
      },
      "source": [
        "score of 1.0 indicating total shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4SUFEE0OEaL",
        "colab_type": "text"
      },
      "source": [
        "# Identifying problematic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDjhkdGSEhs8",
        "colab_type": "code",
        "outputId": "04eceb12-d09a-4ec5-af71-fbc953902dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "y = concat_df['is_test']\n",
        "model = RandomForestClassifier(n_estimators = 50, max_depth = 5,min_samples_leaf = 5)\n",
        "drop_list = []\n",
        "for i in concat_df.columns:\n",
        "  score = cross_val_score(model,pd.DataFrame(concat_df[i]),y,cv=2,scoring='roc_auc')\n",
        "  if (np.mean(score) > 0.8):\n",
        "    drop_list.append(i)\n",
        "    print(i,np.mean(score))\n",
        "\n",
        "drop_list.remove('is_test')\n",
        "drop_list"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sensor_06 0.9765147393716356\n",
            "sensor_07 0.8110294317615871\n",
            "sensor_11 0.8197349327674084\n",
            "sensor_13 0.898767418602145\n",
            "sensor_30 0.8036164842291849\n",
            "sensor_35 0.8663917571228893\n",
            "sensor_37 0.9115711466185406\n",
            "sensor_46 0.8026958572570748\n",
            "sensor_48 0.896410109205826\n",
            "sensor_50 0.933620793996611\n",
            "is_test 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sensor_06',\n",
              " 'sensor_07',\n",
              " 'sensor_11',\n",
              " 'sensor_13',\n",
              " 'sensor_30',\n",
              " 'sensor_35',\n",
              " 'sensor_37',\n",
              " 'sensor_46',\n",
              " 'sensor_48',\n",
              " 'sensor_50']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LdcKTwRPNJT",
        "colab_type": "text"
      },
      "source": [
        "# Determining the importance of the drifting features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdFThDDcdmCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_data_treatment(df)\n",
        "number = LabelEncoder()\n",
        "label_encoding(df, number)\n",
        "\n",
        "train, test = train_test_split(df, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSXYm2OmVhcZ",
        "colab_type": "code",
        "outputId": "9197b33f-9ab5-4694-d589-e83bb41155e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(train.drop('machine_status',axis=1),train['machine_status'])\n",
        "pred = rf.predict(test.drop('machine_status', axis=1))\n",
        "\n",
        "correct_predictions = 0\n",
        "for i in range(len(pred)):\n",
        "  if pred[i] == test.iloc[i]['machine_status']:\n",
        "    correct_predictions+=1\n",
        "\n",
        "print('The accuracy of the model with all features is {}'.format(correct_predictions / len(pred)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model with all features is 0.9989832970225128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYyMAJIfF2eT",
        "colab_type": "code",
        "outputId": "e1ca7d43-23e1-4560-edbf-740b3bc85e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "features = train.drop('machine_status',axis=1).columns.values\n",
        "imp = rf.feature_importances_\n",
        "indices = np.argsort(imp)[::-1][:20]\n",
        "\n",
        "#plot\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(range(len(indices)), imp[indices], color = 'b', align='center')\n",
        "plt.xticks(range(len(indices)), features[indices], rotation='vertical')\n",
        "plt.xlim([-1,len(indices)])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGZ0pB3iDBIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_important = drop_list[:]\n",
        "non_important.remove('sensor_13')\n",
        "non_important.remove('sensor_48')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWK0BjxDGWQ4",
        "colab_type": "text"
      },
      "source": [
        "This way, it is possible to conclude that sensor_13 is the only relatively important features among the drifting ones. That way, it is removed from the list of features to be dropped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srMayEYSGx6L",
        "colab_type": "text"
      },
      "source": [
        "## Testing the performance without the problem features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cy1syswKoBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_perfomance(dropped_features):\n",
        "  drift_train = train.drop(columns=dropped_features)\n",
        "  drift_test = test.drop(columns=dropped_features)\n",
        "\n",
        "  rf = RandomForestClassifier()\n",
        "  rf.fit(drift_train.drop('machine_status',axis=1),drift_train['machine_status'])\n",
        "  pred = rf.predict(drift_test.drop('machine_status', axis=1))\n",
        "\n",
        "  correct_predictions = 0\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i] == drift_test.iloc[i]['machine_status']:\n",
        "      correct_predictions+=1\n",
        "\n",
        "  print('Score is {}'.format(correct_predictions / len(pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFbP3bXcHCww",
        "colab_type": "code",
        "outputId": "7f9d8efc-6c21-4b01-a6fc-f8831adba513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Removed all drifting features')\n",
        "test_perfomance(drop_list)\n",
        "print('Removed only non-important drifting features')\n",
        "test_perfomance(non_important)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removed all drifting features\n",
            "Score is 0.9990740740740741\n",
            "Removed only non-important drifting features\n",
            "Score is 0.9991648511256355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OepS51o8pC4F",
        "colab_type": "text"
      },
      "source": [
        "## Fixed LearnNSE class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjUpnBxfpMbs",
        "colab_type": "text"
      },
      "source": [
        "Due to a bug on the current version of the LearnNSE class of scikit-multiflow, this fix has to be included in the code for it to run properly. Whenever this fix is deployed on a stable version, this code is redundant and should be deleted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCwAo4seo_wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy as cp\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from skmultiflow.core import BaseSKMObject, ClassifierMixin, MetaEstimatorMixin\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "def LearnNSE(base_estimator=DecisionTreeClassifier(), window_size=250, slope=0.5, crossing_point=10, n_estimators=15,\n",
        "             pruning=None):     # pragma: no cover\n",
        "    warnings.warn(\"'LearnNSE' has been renamed to 'LearnPPNSEClassifier' in v0.5.0.\\n\"\n",
        "                  \"The old name will be removed in v0.7.0\", category=FutureWarning)\n",
        "    return LearnPPNSEClassifier(base_estimator=base_estimator,\n",
        "                                window_size=window_size,\n",
        "                                slope=slope,\n",
        "                                crossing_point=crossing_point,\n",
        "                                n_estimators=n_estimators,\n",
        "                                pruning=pruning)\n",
        "\n",
        "\n",
        "class LearnPPNSEClassifier(BaseSKMObject, ClassifierMixin, MetaEstimatorMixin):\n",
        "    \"\"\" Learn++.NSE ensemble classifier.\n",
        "    Learn++.NSE [1]_ is an ensemble of classifiers for incremental learning\n",
        "    from non-stationary environments (NSEs) where the underlying data\n",
        "    distributions change over time. It learns from consecutive batches of data\n",
        "    that experience constant or variable rate of drift, addition or deletion\n",
        "    of concept classes, as well as cyclical drift.\n",
        "    References\n",
        "    ----------\n",
        "    .. [1] Ryan Elwell and Robi Polikar. Incremental learning of concept drift in\n",
        "       non-stationary environments. IEEE Transactions on Neural Networks,\n",
        "       22(10):1517-1531, October 2011. ISSN 1045-9227. URL\n",
        "       http://dx.doi.org/10.1109/TNN.2011.2160459\n",
        "    Parameters\n",
        "    ----------\n",
        "    base_estimator: StreamModel or sklearn.BaseEstimator (default=DecisionTreeClassifier)\n",
        "        Each member of the ensemble is an instance of the base estimator.\n",
        "    n_estimators: int (default=15)\n",
        "        The number of base estimators in the ensemble.\n",
        "    window_size: int (default=250)\n",
        "        The size of the training window (batch), in other words, how many instances are kept for training.\n",
        "    crossing_point: float (default=0.5)\n",
        "        Halfway crossing point of the sigmoid function controlling the number of previous\n",
        "        periods taken into account during weighting.\n",
        "    slope: float (default=0.5)\n",
        "        Slope of the sigmoid function controlling the number\n",
        "        of previous periods taken into account during weighting.\n",
        "    pruning: string (default=None)\n",
        "        Classifiers pruning strategy to be used.\n",
        "        pruning=None: Don't prune classifiers\n",
        "        pruning='age': Age-based\n",
        "        pruning='error': Error-based\n",
        "    Examples\n",
        "    --------\n",
        "    .. code-block:: python\n",
        "       # Imports\n",
        "       from skmultiflow.data import SEAGenerator\n",
        "       from skmultiflow.meta import LearnPPNSEClassifier\n",
        "       # Setup a data stream\n",
        "       stream = SEAGenerator(random_state=1)\n",
        "       # Setup Dynamic Weighted Majority Ensemble Classifier\n",
        "       learn_pp_nse = LearnPPNSEClassifier()\n",
        "       # Setup varibles to control loop and track performance\n",
        "       n_samples = 0\n",
        "       correct_cnt = 0\n",
        "       max_samples = 200\n",
        "       # Train the classifier with the samples provided by the data stream\n",
        "       while n_samples < max_samples and stream.has_more_samples():\n",
        "           X, y = stream.next_sample()\n",
        "           y_pred = learn_pp_nse.predict(X)\n",
        "           if y[0] == y_pred[0]:\n",
        "               correct_cnt += 1\n",
        "           learn_pp_nse = learn_pp_nse.partial_fit(X, y, classes=stream.target_values)\n",
        "           n_samples += 1\n",
        "       # Display results\n",
        "       print('{} samples analyzed.'.format(n_samples))\n",
        "       print('LearnPP.NSE accuracy: {}'.format(correct_cnt / n_samples))\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 base_estimator=DecisionTreeClassifier(),\n",
        "                 window_size=250,\n",
        "                 slope=0.5,\n",
        "                 crossing_point=10,\n",
        "                 n_estimators=15,\n",
        "                 pruning=None):\n",
        "        super().__init__()\n",
        "        self.ensemble = []\n",
        "        self.ensemble_weights = []\n",
        "        self.bkts = []\n",
        "        self.wkts = []\n",
        "        self.buffer = []\n",
        "        self.window_size = window_size\n",
        "        self.slope = slope\n",
        "        self.crossing_point = crossing_point\n",
        "        self.n_estimators = n_estimators\n",
        "        self.pruning = pruning\n",
        "        self.X_batch = []\n",
        "        self.y_batch = []\n",
        "        self.instance_weights = []\n",
        "        self.base_estimator = cp.deepcopy(base_estimator)\n",
        "        self.classes = None\n",
        "\n",
        "    @staticmethod\n",
        "    def _train_model(estimator, X, y, classes=None):\n",
        "        try:\n",
        "            estimator.fit(X, y, classes=classes)\n",
        "        except TypeError:\n",
        "            try:\n",
        "                estimator.fit(X, y)\n",
        "            except NotImplementedError:\n",
        "                estimator.partial_fit(X, y, classes=classes)\n",
        "\n",
        "    def partial_fit(self, X, y=None, classes=None, sample_weight=None):\n",
        "        \"\"\"\n",
        "        Partially fits the model, based on the X and y matrix.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (n_samples, n_features)\n",
        "            Features matrix used for partially updating the model.\n",
        "        y: Array-like\n",
        "            An array-like of all the class labels for the samples in X.\n",
        "        classes: numpy.ndarray, optional (default=None)\n",
        "            Array with all possible/known class labels. This is an optional parameter, except\n",
        "            for the first partial_fit call where it is compulsory.\n",
        "        sample_weight: NOT used (default=None)\n",
        "        Raises\n",
        "        ------\n",
        "        RuntimeError:\n",
        "            A RuntimeError is raised if the 'classes' parameter is not\n",
        "            passed in the first partial_fit call, or if they are passed in further\n",
        "            calls but differ from the initial classes list passed.\n",
        "            A RuntimeError is raised if the base_estimator is too weak. In other word,\n",
        "            it has too low accuracy on the dataset.\n",
        "        Returns\n",
        "        -------\n",
        "        LearnPPNSEClassifier\n",
        "            self\n",
        "        \"\"\"\n",
        "\n",
        "        N, _ = X.shape\n",
        "        if self.classes is None:\n",
        "            if classes is None:\n",
        "                raise RuntimeError(\"Should pass the classes in the first partial_fit call\")\n",
        "            else:\n",
        "                self.classes = classes\n",
        "\n",
        "        for i in range(N):\n",
        "            self.X_batch.append(X[i])\n",
        "            self.y_batch.append(y[i])\n",
        "            mt = len(self.y_batch)\n",
        "\n",
        "            if mt == self.window_size:\n",
        "                self.X_batch = np.array(self.X_batch)\n",
        "                self.y_batch = np.array(self.y_batch)\n",
        "\n",
        "                classifier = cp.deepcopy(self.base_estimator)\n",
        "\n",
        "                if len(self.ensemble) > 0:\n",
        "                    # Compute the error of the existing ensemble on the new data\n",
        "                    votes = self.predict(self.X_batch)\n",
        "\n",
        "                    et = np.sum(votes != self.y_batch) / mt\n",
        "\n",
        "                    # Update and normalize instance weights\n",
        "                    self.instance_weights = np.ones(mt) / mt\n",
        "                    self.instance_weights[votes == self.y_batch] = et / mt\n",
        "\n",
        "                    # normalize instance weights (distribution)\n",
        "                    sum_weights = np.sum(self.instance_weights)\n",
        "                    if sum_weights > 0:\n",
        "                        self.instance_weights = self.instance_weights / sum_weights\n",
        "\n",
        "                    # Train base classifier with Dt\n",
        "                    self._train_model(classifier, self.X_batch, self.y_batch, classes=self.classes)\n",
        "\n",
        "                else:\n",
        "                    # First run! train the classifier on the instances with the same weight\n",
        "                    self.instance_weights = np.ones(mt) / mt\n",
        "\n",
        "                    self._train_model(classifier, self.X_batch, self.y_batch, classes=self.classes)\n",
        "\n",
        "                self.ensemble.append(classifier)\n",
        "                self.bkts.append([])\n",
        "                self.wkts.append([])\n",
        "                self.ensemble_weights = []\n",
        "\n",
        "                t = len(self.ensemble)\n",
        "                max_error = -np.inf\n",
        "                error_index = -1\n",
        "\n",
        "                # Evaluate all existing classifiers on the new dataset\n",
        "                for k in range(1, t + 1):\n",
        "                    pred = self.ensemble[k - 1].predict(self.X_batch)\n",
        "                    ekt = np.sum(self.instance_weights[pred != self.y_batch])\n",
        "\n",
        "                    if k == t and ekt > 0.5:\n",
        "                        # Generate a new classifier\n",
        "                        classifier = cp.deepcopy(self.base_estimator)\n",
        "                        self._train_model(classifier, self.X_batch, self.y_batch, classes=self.classes)\n",
        "                        self.ensemble[k - 1] = classifier\n",
        "                    elif ekt > 0.5:\n",
        "                        ekt = 0.5\n",
        "\n",
        "                    # Storing the index of the classifier with higher error in case of error-based pruning\n",
        "                    if ekt > max_error:\n",
        "                        max_error = ekt\n",
        "                        error_index = k\n",
        "\n",
        "                    # Normalize errors\n",
        "                    bkt = ekt / (1 - ekt)\n",
        "\n",
        "                    # store normalized error for this classifier\n",
        "                    nbkts = self.bkts[k - 1]\n",
        "                    nbkts.append(bkt)\n",
        "\n",
        "                    # compute the weighted normalized errors for kth classifier h_k\n",
        "                    wkt = 1.0 / (1.0 + np.exp(-self.slope * (t - k - self.crossing_point)))\n",
        "                    weights = self.wkts[k - 1]\n",
        "                    weights.append(wkt / (np.sum(weights) + wkt))\n",
        "\n",
        "                    sbkt = np.sum(np.array(nbkts) * np.array(weights)) + 1e-50\n",
        "\n",
        "                    # Calculate classifier voting weights\n",
        "                    self.ensemble_weights.append(np.log(1.0 / sbkt))\n",
        "\n",
        "                # Ensemble pruning\n",
        "\n",
        "                if self.pruning == 'age' and t > self.n_estimators:\n",
        "                    # Age-based\n",
        "                    self.ensemble.pop(0)\n",
        "                    self.ensemble_weights.pop(0)\n",
        "                    self.bkts.pop(0)\n",
        "                    self.wkts.pop(0)\n",
        "                elif self.pruning == 'error' and t > self.n_estimators:\n",
        "                    # Error-based\n",
        "                    self.ensemble.pop(error_index - 1)\n",
        "                    self.ensemble_weights.pop(error_index - 1)\n",
        "                    self.bkts.pop(error_index - 1)\n",
        "                    self.wkts.pop(error_index - 1)\n",
        "\n",
        "                # Reset the buffer\n",
        "                self.X_batch = []\n",
        "                self.y_batch = []\n",
        "        return self\n",
        "\n",
        "    def __vote_proba(self, X, t, classes):\n",
        "        res = []\n",
        "        for m in range(len(X)):\n",
        "            votes = np.zeros((1, len(classes)))\n",
        "            for i in range(t):\n",
        "                if self.ensemble_weights[i] > 0:\n",
        "                    h = self.ensemble[i]\n",
        "                    y_predicts = h.predict_proba(X[m].reshape(1, -1))\n",
        "                    y_predicts /= np.linalg.norm(y_predicts, ord=1, axis=1, keepdims=True)\n",
        "                    try:\n",
        "                        votes += self.ensemble_weights[i] * y_predicts\n",
        "                    except ValueError:\n",
        "                        if hasattr(h, 'classes_'):  # sklearn learner\n",
        "                            obs_classes = h.classes_\n",
        "                        elif hasattr(h, 'classes'):  # skmultiflow learner\n",
        "                            obs_classes = h.classes\n",
        "                        else:\n",
        "                            raise AttributeError(\n",
        "                                'The base estimator does not define the \"classes\" or \"classes_\" ' +\n",
        "                                'parameter. The base estimator must specify the classes it has ' +\n",
        "                                'observed during the training stage in order to maintain ' +\n",
        "                                'consistency across the ensemble.'\n",
        "                            )\n",
        "                        votes += self.ensemble_weights[i] * \\\n",
        "                            self._fill_missing_probs(\n",
        "                                y_predicts, obs_classes, self.classes\n",
        "                            )\n",
        "\n",
        "            res.append(votes.reshape(len(classes)))\n",
        "        return np.array(res)\n",
        "\n",
        "    def _fill_missing_probs(self, probs, obs_classes, all_classes):\n",
        "        proba_ordered = np.zeros(\n",
        "            (probs.shape[0], len(all_classes)), dtype=np.float\n",
        "        )\n",
        "        sorted_classes = np.argsort(all_classes)\n",
        "        # Find positions to insert existing classes' probs to the complete set\n",
        "        # of classes\n",
        "        idx = sorted_classes[np.searchsorted(all_classes, obs_classes, sorter=sorted_classes)]\n",
        "        proba_ordered[:, idx] = probs\n",
        "        return proba_ordered\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\" Predicts the probability of each sample belonging to each one of the\n",
        "        known classes.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (n_samples, n_features)\n",
        "            A matrix of the samples we want to predict.\n",
        "        Returns\n",
        "        -------\n",
        "        numpy.ndarray\n",
        "            An array of shape (n_samples, n_features), in which each outer entry is\n",
        "            associated with the X entry of the same index. And where the list in\n",
        "            index [i] contains len(self.target_values) elements, each of which represents\n",
        "            the probability that the i-th sample of X belongs to a certain label.\n",
        "        \"\"\"\n",
        "\n",
        "        if not self.ensemble:\n",
        "            return np.zeros((len(X), 1))\n",
        "\n",
        "        return self.__vote_proba(X, len(self.ensemble), self.classes)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\" Predicts the class for a given sample by majority vote from all\n",
        "        the members of the ensemble.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: numpy.ndarray of shape (n_samples, n_features)\n",
        "            A matrix of the samples we want to predict.\n",
        "        Returns\n",
        "        -------\n",
        "        numpy.ndarray\n",
        "            A numpy.ndarray with the label prediction for all the samples in X.\n",
        "        \"\"\"\n",
        "\n",
        "        votes = self.predict_proba(X)\n",
        "        return np.argmax(votes, axis=1)\n",
        "\n",
        "    def reset(self):\n",
        "        self.ensemble = []\n",
        "        self.ensemble_weights = []\n",
        "        self.bkts = []\n",
        "        self.wkts = []\n",
        "        self.X_batch = []\n",
        "        self.y_batch = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkxp0KUcsh3K",
        "colab_type": "text"
      },
      "source": [
        "## Testing the perfomance of Learn++.NSE, with and without drifting features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ8Ln2YBd6Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learn_nse_method(train_df):\n",
        "  learn_nse = LearnNSE()\n",
        "\n",
        "  n_samples = 0\n",
        "  correct_cnt = 0\n",
        "\n",
        "  for i in range(len(train_df)):\n",
        "    sample = train_df.iloc[[i]]\n",
        "    X = sample.drop('machine_status',axis=1)\n",
        "    y = sample['machine_status']\n",
        "    \n",
        "    y_pred = learn_nse.predict(X.to_numpy())\n",
        "\n",
        "    if y.values[0] == y_pred[0]:\n",
        "      correct_cnt += 1\n",
        "\n",
        "    learn_nse = learn_nse.partial_fit(X.to_numpy(), y.to_numpy(), classes=[0, 1, 3])\n",
        "    n_samples += 1\n",
        "  \n",
        "  print('{} samples analyzed.'.format(n_samples))\n",
        "  print('LearnPP.NSE accuracy: {}'.format(correct_cnt / n_samples))\n",
        "\n",
        "  return learn_nse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwe_cYUdihxx",
        "colab_type": "code",
        "outputId": "5f098623-9ba6-436d-c69b-0821507de57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "learn_nse = learn_nse_method(train)\n",
        "\n",
        "pred = learn_nse.predict(test.drop('machine_status',axis=1).to_numpy())\n",
        "\n",
        "correct_predictions = 0\n",
        "for i in range(len(pred)):\n",
        "  if pred[i] == test.iloc[i]['machine_status']:\n",
        "    correct_predictions+=1\n",
        "\n",
        "print('Score is {}'.format(correct_predictions / len(pred)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: 'LearnNSE' has been renamed to 'LearnPPNSEClassifier' in v0.5.0.\n",
            "The old name will be removed in v0.7.0\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "165240 samples analyzed.\n",
            "LearnPP.NSE accuracy: 0.8813725490196078\n",
            "Score is 0.9986201888162672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pB1LLUbJpHMO"
      },
      "source": [
        "Using Learn++.NSE without drifting feature\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpXiVFn4qpCM",
        "colab_type": "code",
        "outputId": "386331f3-ab3d-44c0-ff6d-d4ef24447edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "drift_train = train.drop(columns=non_important)\n",
        "drift_test = test.drop(columns=non_important)\n",
        "\n",
        "learn_nse = learn_nse_method(drift_train)\n",
        "\n",
        "pred = learn_nse.predict(test.drop('machine_status',axis=1).to_numpy())\n",
        "\n",
        "correct_predictions = 0\n",
        "for i in range(len(pred)):\n",
        "  if pred[i] == drift_test.iloc[i]['machine_status']:\n",
        "    correct_predictions+=1\n",
        "\n",
        "print('Score is {}'.format(correct_predictions / len(pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: 'LearnNSE' has been renamed to 'LearnPPNSEClassifier' in v0.5.0.\n",
            "The old name will be removed in v0.7.0\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "165240 samples analyzed.\n",
            "LearnPP.NSE accuracy: 0.8860869038973614\n",
            "Score is 0.9986201888162672\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}